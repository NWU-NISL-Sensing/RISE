## Dataset download link (Baidu Disk)：

##### **link：**https://pan.baidu.com/s/1AIvyei-0XmO70_cASTVkIg 

##### **password：**dl1h

## Datasets description:

#### Case study 1: Gesture recognition

**WiG&WiAG** file name is in this form: a_b_c.dat, where 'a' represents gesture id, between 'gesture1' and 'gesture6'; 'b' represents scene id, between 's1' and 's5'; 'c' represents instance id. 
<u>Gesture:</u> gesture1: Push and Pull; gesture2: Draw a Circle; gesture3: Throw; gesture4: Slide; gesture5: Sweep; gesture6: Draw Zigzag;
<u>Scene:</u> We changed the location where the gestures were performed ( S1, S2, S3 ) and added chairs in different positions to mimic multi-path ( S4, S5 ) when the gestures were performed at location S1.

**TACT&AllSee** file name is in this form: a_b_c.txt, where 'a' represents gesture id, between 'gesture1' and 'gesture6'; 'b' represents scene id, between 's1' and 's5'; 'c' represents instance id. 
<u>Gesture:</u> gesture1: Push and Pull; gesture2: Draw a Circle; gesture3: Throw; gesture4: Slide; gesture5: Sweep; gesture6: Draw Zigzag;
<u>Scene:</u> We changed the location where the gestures were performed ( S1, S2, S3 ) and added chairs in different positions to mimic multi-path ( S4, S5 ) when the gestures were peformed at location S1.

**EI** file name is in this form: a_b_c.mat, where 'a' represents gesture id, between 'gesture1' and 'gesture6'; 'b' represents scene id, between 's1' and 's5'; 'c' represents instance id. 
<u>Gesture:</u> gesture1: Push and Pull; gesture2: Draw a Circle; gesture3: Throw; gesture4: Slide; gesture5: Sweep; gesture6: Draw Zigzag;
<u>Scene:</u> We changed the location where the gestures were performed ( S1, S2, S3 ) and added chairs in different positions to mimic multi-path ( S4, S5 ) when the gestures were peformed at location S1. 

#### Case study 2: Gait recognition

**WiWho&WifiU** file name is in this form: a_b_c.dat, where 'a' represents user's id, between 'u1' and 'u15'; 'b' represents scene id, between 's1' and 's5'; 'c' represents instance id.
<u>Scene:</u> We asked participants to walk along different paths ( S1, S2, S3 ) and added chairs in different positions to mimic multi-path ( S4, S5 ) when participants were walking along path S1.

#### Case study 3: Activity recognition

**VibWrite** file name is in this form: a_b_c.mat, where 'a' represents user's id, between 'u1' and 'u15'; 'b' represents scene id, between '1' and '14'; 'c' represents grid point id, between '0' and '9'.  
<u>Scene:</u> We ensured that the sensing area was free of obstacles ( N ) or placing a glass of water at four different locations ( 1, 2, 3, 4 ). In addition, we also asked participants to perform experiments with different fingers, i.e., scene id '5' to '14', when the sensing area was free of obstacles ( N ). 

**Taprint** file name is in this form: a_b_c.txt, where 'a' represents user's id, between 'u1' and 'u15'; 'b' represents scene id, between '1' and '5'; 'c' represents knuckle id, between '1' and '12'.  
<u>Scene:</u> This case study involves multiple indoor and outdoor settings with dry and wet hands. For the indoor setting, we asked participants to tap the 12 knuckles on their hands with standard force ( S ) and a different force ( D ) when with a dry or a wet ( W ) hand. Then, we asked participants to tap the 12 knuckles with standard force during the outdoor setting when walking with a dry hand ( M ). '1':S;'2':D;'4':W;'5':M. In addition, scene id '3' represents performing experiments while going up stairs.

**UDO-Free** file name is in this form: a_b_c.txt, where 'a' represents user's id, between 'u1' and 'u15'; 'b' represents action id, including, 'bike','run','sit','stand','walk'; 'c' represents scene id, between '1' and '4'.   
<u>Scene:</u> We asked participants to put the mobile phone in their right and left pockets ( RP, LP ) to perform the set of actions supported by UDO-Free. Then, we asked participants to place the phone in the right pocket to perform the “Sitting” and “Biking” actions using different chairs ( DC ) and bicycles ( DB ).  '1':RP;'2':'LP';'3':DC;'4':DB. 

**M-Touch** file name is in this form: a_b_c.txt, where 'a' represents user's id, between 'u1' and 'u15'; 'b' represents finger's id, including, 'forefinger', 'middlefinger', 'ringfinger',  and  'littlefinger'; 'c' represents scene id, between '1' and '6'.  
<u>Scene:</u> We first asked participants to hold the smartphone in their hands and perform an action in different postures, including sitting ( S ), standing ( DP ), and walking ( M ). Then, we asked our participants to perform each action in a sitting posture while the phone was placed on the table ( T ). '1' and '2': S; '3' and '4' : DP; '5': M;'6':T.  In order to make participants familiar with the experiment process more quickly, '1' and '2' repeated the experiment twice in the same scene, as did '3' and '4'.











