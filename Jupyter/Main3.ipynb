{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e606f7",
   "metadata": {},
   "source": [
    "# Robust Wireless Sensing using Probabilistic and Statistical Assessments ：Artifact - Interactive Demo\n",
    "<img src=\"./overview2.jpg\" width=\"100%\" style=\"float:left\" />\n",
    "\n",
    "\n",
    "\n",
    "## Step 1. Training the underlying model and use it to predict test samples.\n",
    "\n",
    "## Step 2. Training an anomaly detector for each class according to the training samples.\n",
    "## Step 3. Evaluate the ability of the underlying model to predict the test sample.\n",
    "## Step 4. Performance of the RISE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd450db7",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "This interactive Jupyter notebook provides an example to show the performance of RISE. \n",
    "## Instructions for Experimental Workflow:\n",
    "Select each cell in turn and use “Cell” > “Run Cell” from the menu to run specific cells. Note that some cells depend on previous cells being executed. If any errors occur, ensure all previous cells have been executed.\n",
    "## Important Notes\n",
    "#### Some cells can take a few minutes to complete; please wait for the results until step to the next cell.\n",
    "\n",
    "## Step 1. Performance of the underlying model without RISE\n",
    "Here we provide the results of each experimental environment for each case study.\n",
    "You can change the scene names at two places in each piece of code to get results for different scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762ae2d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------  The performance of the underlying model without RISE --------\n",
      "\n",
      "The accuracy without RISE:  0.85\n",
      "Confusion matrix without RISE: \n",
      " [[30  0  0  0  0  0]\n",
      " [ 0 30  0  0  0  0]\n",
      " [ 6  0 24  0  0  0]\n",
      " [17  0  0 13  0  0]\n",
      " [ 0  0  0  0 30  0]\n",
      " [ 0  0  0  4  0 26]]\n"
     ]
    }
   ],
   "source": [
    "#Import different data sets\n",
    "\n",
    "##-------------------------------Case study 1: Gesture recognition----------------------------------------##\n",
    "\n",
    "#### For WiG, you can change S1  S2  S3  S4  S5\n",
    "filepath_AR = '/root/RISE-Version2/Jupyter/WiG_test/S1/'\n",
    "from WiG_test.S1.test_start import start\n",
    "x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "# ### For WiAG, you can change S1  S2  S3  S4  S5\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/WiAG_test/S4/'\n",
    "# from WiAG_test.S4.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "# #### For WiAG_C, you can change L1 L2  L3  L4  L5\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/WiAG_C_test/L5/'\n",
    "# from WiAG_C_test.L5.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()  \n",
    "\n",
    "# #### For WiAG_O, you can change L1 L2  L3  L4  L5\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/WiAG_O_test/L4/'\n",
    "# from WiAG_O_test.L4.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start() \n",
    "\n",
    "# #### For TACT, you can change S1 S2 S3 S4 S5 \n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/TACT_test/S1/'\n",
    "# from TACT_test.S1.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()  \n",
    "\n",
    "# #### For AllSee, you can change S1 S2 S3 S4 S5\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/AllSee_test/S5/'\n",
    "# from AllSee_test.S5.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start() \n",
    "\n",
    "# #### For EI, you can change S1 S2 S3 S4 S5 \n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/EI_test/S2/'\n",
    "# from EI_test.S2.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start(filepath_AR) \n",
    "\n",
    "##-------------------------------Case study 2: Gait recognition----------------------------------------##\n",
    "\n",
    "# #### For WiWho, you can change S1 S2 S3 S4 S5\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/WiWho_test/S5/'\n",
    "# from WiWho_test.S5.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start() \n",
    "\n",
    "# #### For WifiU, you can change S1 S2 S3 S4 S5\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/WifiU_test/S5/'\n",
    "# from WifiU_test.S4.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "\n",
    "##-------------------------------Case study 3: Activity recognition----------------------------------------##\n",
    "\n",
    "# #### For VibWrite_R, you can change N _1 _2 _3 _4\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/VibWrite_R_test/_4/'\n",
    "# from VibWrite_R_test._4.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "# #### For VibWrite_A, you can change N _1 _2 _3 _4\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/VibWrite_A_test/_4/'\n",
    "# from VibWrite_A_test._4.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "# #### For Taprint_R, you can change S D M W \n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/Taprint_R_test/W/'\n",
    "# from Taprint_R_test.W.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "# #### For Taprint_A, you can change S D M W \n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/Taprint_A_test/W/'\n",
    "# from Taprint_A_test.W.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n",
    "\n",
    "# #### For UDO_Free, you can change RP LP DC DB \n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/UDO_Free/DB/'\n",
    "# from UDO_Free.DB.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_    dif,class_num,class_index = start()\n",
    "\n",
    "# #### For M_Touch, you can change S DP T M\n",
    "# filepath_AR = '/root/RISE-Version2/Jupyter/M_Touch/M/'\n",
    "# from M_Touch.M.test_start import start\n",
    "# x_train1, y_train1, x_test1, y_test1, myclassifier, y_true_dif, y_pred_dif,class_num,class_index = start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c419d08",
   "metadata": {},
   "source": [
    "## Step 2. Training an Anomaly Detector for each class according to the training data.\n",
    "For convenience, we have saved trained anomaly detectors for each experimental environment. However, you can also run the following cell to train the anomaly detector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbda47f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_p_prob_0\n",
      "\n",
      "clf_p_prob_1\n",
      "\n",
      "clf_p_prob_2\n",
      "\n",
      "clf_p_prob_3\n",
      "\n",
      "clf_p_prob_4\n",
      "\n",
      "clf_p_prob_5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tt in range(class_num):\n",
    "    print('clf_p_prob_'+ str(tt)+'\\n')\n",
    "\n",
    "# ############################ Trainning Anomaly Detector  ###############################  \n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# import numpy as np\n",
    "# from sklearn import preprocessing\n",
    "# from nonconformist.nc import MarginErrFunc\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Numerical issues were encountered \")\n",
    "# import sys\n",
    "# sys.path.insert(0,'/root/RISE-Version2/')\n",
    "# from Statistical_vector.statistical_vector import train_statistical_vector, test_statistical_vector_param, non_condition_p\n",
    "# import random\n",
    "# from sklearn import svm\n",
    "# import joblib\n",
    "# import sklearn.ensemble\n",
    "# from sklearn import neighbors\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import  AdaBoostClassifier\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# ## Probability vector and statistical vector are calculated according to the training data\n",
    "# skf = StratifiedKFold(n_splits=3, random_state=0,shuffle=True)\n",
    "# cal_proba = np.empty(shape=[0, (class_num)*4])\n",
    "# cal_score = np.empty(shape=[0, 1*4])\n",
    "# train_proba = np.empty(shape=[0, (class_num)*4])\n",
    "# train_nonconformity = np.empty(shape=[0, (class_num)*4])\n",
    "# train_p = np.empty(shape=[0, (class_num)*4])\n",
    "# cal_label = np.empty(shape=[0,1])\n",
    "# train_label = np.empty(shape=[0,1])\n",
    "# for train_index, cal_index in skf.split(x_train1, y_train1):\n",
    "#     data_train = x_train1[train_index, :] \n",
    "#     label_train = y_train1[train_index]\n",
    "#     data_cal = x_train1[cal_index, :]\n",
    "#     label_cal = y_train1[cal_index]\n",
    "    \n",
    "#     train_p1_svm_, train_proba1_svm_ = train_statistical_vector(data_train, label_train, data_cal, label_cal, \n",
    "#                        classification_model = myclassifier[0], non_Func = MarginErrFunc(), significance=None) \n",
    "#     train_p1_rf_, train_proba1_rf_ = train_statistical_vector(data_train, label_train, data_cal, label_cal, \n",
    "#                        classification_model = myclassifier[1], non_Func = MarginErrFunc(), significance=None) \n",
    "#     train_p1_lr_, train_proba1_lr_ = train_statistical_vector(data_train, label_train, data_cal, label_cal, \n",
    "#                        classification_model = myclassifier[4], non_Func = MarginErrFunc(), significance=None)\n",
    "#     train_p1_gbc_, train_proba1_gbc_ = train_statistical_vector(data_train, label_train, data_cal, label_cal, \n",
    "#                        classification_model = myclassifier[5], non_Func = MarginErrFunc(), significance=None)\n",
    "    \n",
    "#     train_proba1 = np.hstack((train_proba1_svm_, train_proba1_rf_, train_proba1_lr_, train_proba1_gbc_))\n",
    "#     train_p1 = np.hstack((train_p1_svm_, train_p1_rf_, train_p1_lr_, train_p1_gbc_))\n",
    "#     train_proba = np.append(train_proba, train_proba1, axis=0)  \n",
    "#     train_p = np.append(train_p, train_p1, axis=0)  \n",
    "#     train_label = np.append(train_label,y_train1[train_index]) \n",
    "    \n",
    "# p_thr = 0.1\n",
    "# rows_ = []  \n",
    "# for row_ in range(train_p.shape[0]):\n",
    "#     if (max(train_p[row_,0:0+class_num]) > p_thr) & (max(train_p[row_,class_num:class_num*1+class_num]) > p_thr) \\\n",
    "#         & (max(train_p[row_,class_num*2:class_num*2+class_num]) > p_thr) & (max(train_p[row_,class_num*3:class_num*3+class_num]) > p_thr) :               \n",
    "#             rows_.append(row_)\n",
    "        \n",
    "# pro_n_p = np.hstack((train_proba, train_p))\n",
    "# group_it = pro_n_p[rows_,:] \n",
    "# train_label1 = train_label[rows_] \n",
    "\n",
    "# group_it = preprocessing.scale(group_it)\n",
    "   \n",
    "# index = [t for t in range(group_it.shape[0])] \n",
    "# random.shuffle(index)\n",
    "# group_it1 = group_it[index] \n",
    "# train_p_lable1 = train_label1[index]\n",
    "\n",
    "\n",
    "\n",
    "# ####Training an anomaly detector for each class\n",
    "\n",
    "# ##Generalize probability vectors and statistical vectors for each class\n",
    "# names = locals()\n",
    "# fe_p_prob = np.hstack((train_p_lable1.reshape(-1,1),group_it1))\n",
    "# for tt in range(class_num):\n",
    "#     names['fe_p_prob_%s'%tt] = fe_p_prob[fe_p_prob[:,0]==tt]\n",
    "#     names['fe_p_prob_%s'%tt] = np.delete(names['fe_p_prob_%s'%tt], 0, 1)  \n",
    "\n",
    "# print('\\n---------------  Training one-class SVM model for each class -----------------\\n')    \n",
    "# ##training one-class SVM model for each class\n",
    "# for tt in range(class_num):\n",
    "#     names['./save_model/clf_p_prob_%s'%tt] = svm.OneClassSVM(nu=0.5,kernel=\"linear\" )\n",
    "#     names['./save_model/clf_p_prob_%s'%tt].fit(names['fe_p_prob_%s'%tt])\n",
    "#     print('clf_p_prob_'+ str(tt)+'\\n')\n",
    "#     ##save one-class SVM model for each class\n",
    "#     joblib.dump(names['./save_model/clf_p_prob_%s'%tt],'./save_model/clf_p_prob_%s'%tt+'.model')\n",
    "    \n",
    "\n",
    "# ##Ensemble Learning\n",
    "# clf_dif1 = sklearn.ensemble.RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "# clf_dif2 = svm.SVC(probability = True, random_state=0)\n",
    "# clf_dif3 = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "# clf_dif4 = LogisticRegression(random_state=0)\n",
    "# clf_dif7 = AdaBoostClassifier(random_state=0)   \n",
    "# clf_pit = VotingClassifier(estimators = [('rf',clf_dif1),('svm',clf_dif2),\n",
    "# ('knn',clf_dif3),('lr',clf_dif4),('AdaBoost',clf_dif7)],voting='hard')      \n",
    "# clf_pit.fit(group_it1,train_p_lable1)\n",
    "# joblib.dump(clf_pit,'./save_model/clf_pit.model') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab9215",
   "metadata": {},
   "source": [
    "## Step 3. Evaluate the ability of the underlying model to predict the test data.\n",
    "For convenience, we have saved the approval or rejection of the predicted results of the test sample by the anomaly detector. Approval is denoted by 1, rejection is denoted by -1.  However, you can also run the following cell to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b883e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1  1 -1  1  1  1\n",
      " -1  1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1  1 -1 -1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "accept_or_reject = np.load(filepath_AR + 'accept_or_reject.npy') \n",
    "print(accept_or_reject)\n",
    "\n",
    "\n",
    "# #####Calculate the probability vector and statistical vector of the test set\n",
    "           \n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# calibration_portion = 0.5\n",
    "# split = StratifiedShuffleSplit(n_splits=1,\n",
    "#                    test_size=calibration_portion)\n",
    "# for train, cal in split.split(x_train1,y_train1):\n",
    "#     cal_scores1_svm = np.empty(cal.reshape(-1,1).shape,dtype=float)\n",
    "#     cal_scores1_rf = np.empty(cal.reshape(-1,1).shape,dtype=float)\n",
    "#     cal_scores1_lr = np.empty(cal.reshape(-1,1).shape,dtype=float)\n",
    "#     cal_scores1_gbc = np.empty(cal.reshape(-1,1).shape,dtype=float)\n",
    "#     test_svmnc1_score = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_rfnc1_score = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_lrnc1_score = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_gbcnc1_score = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_svm1_proba = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_rf1_proba = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_lr1_proba = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     test_gbc1_proba = np.empty(np.array([x_test1.shape[0],class_num]),dtype=float)\n",
    "#     for repeat in range(10):\n",
    "#         train_sample = np.random.choice(train.size, train.size, replace=True)\n",
    "#         data_train = x_train1[train_sample, :]\n",
    "#         label_train = y_train1[train_sample]\n",
    "#         data_cal = x_train1[cal, :]\n",
    "#         label_cal = y_train1[cal]\n",
    "#         data_test = x_test1\n",
    "\n",
    "#         cal_scores_svm, test_svmnc_score, test_svm_proba = test_statistical_vector_param(data_train, label_train,  data_cal, label_cal, data_test,\n",
    "#                  classification_model=myclassifier[0], non_Func = MarginErrFunc(), significance=None)\n",
    "#         cal_scores1_svm = np.hstack((cal_scores1_svm,cal_scores_svm.reshape(-1,1)))\n",
    "#         test_svmnc1_score = np.dstack((test_svmnc1_score,test_svmnc_score))\n",
    "#         test_svm1_proba = np.dstack((test_svm1_proba,test_svm_proba))\n",
    "  \n",
    "#         cal_scores_rf, test_rfnc_score, test_rf_proba = test_statistical_vector_param(data_train, label_train,  data_cal, label_cal, data_test,\n",
    "#                  classification_model=myclassifier[1], non_Func = MarginErrFunc(), significance=None)\n",
    "#         cal_scores1_rf = np.hstack((cal_scores1_rf,cal_scores_rf.reshape(-1,1)))\n",
    "#         test_rfnc1_score = np.dstack((test_rfnc1_score,test_rfnc_score))\n",
    "#         test_rf1_proba = np.dstack((test_rf1_proba,test_rf_proba))\n",
    "          \n",
    "#         cal_scores_lr, test_lrnc_score, test_lr_proba = test_statistical_vector_param(data_train, label_train,  data_cal, label_cal, data_test,\n",
    "#                  classification_model=myclassifier[4], non_Func = MarginErrFunc(), significance=None)\n",
    "#         cal_scores1_lr = np.hstack((cal_scores1_lr,cal_scores_lr.reshape(-1,1)))\n",
    "#         test_lrnc1_score = np.dstack((test_lrnc1_score,test_lrnc_score))\n",
    "#         test_lr1_proba = np.dstack((test_lr1_proba,test_lr_proba))\n",
    "        \n",
    "#         cal_scores_gbc, test_gbcnc_score, test_gbc_proba = test_statistical_vector_param(data_train, label_train,  data_cal, label_cal, data_test,\n",
    "#                  classification_model=myclassifier[5], non_Func = MarginErrFunc(), significance=None)\n",
    "#         cal_scores1_gbc = np.hstack((cal_scores1_gbc,cal_scores_gbc.reshape(-1,1)))\n",
    "#         test_gbcnc1_score = np.dstack((test_gbcnc1_score,test_gbcnc_score))\n",
    "#         test_gbc1_proba = np.dstack((test_gbc1_proba,test_gbc_proba))\n",
    "        \n",
    "        \n",
    "#     ##Nonconformity score of the validation set of the test set    \n",
    "#     cal_scores2_svm = np.mean(np.delete(cal_scores1_svm,0,1), axis=1)\n",
    "#     cal_scores2_rf = np.mean(np.delete(cal_scores1_rf,0,1), axis=1)\n",
    "#     cal_scores2_lr = np.mean(np.delete(cal_scores1_lr,0,1), axis=1)\n",
    "#     cal_scores2_gbc = np.mean(np.delete(cal_scores1_gbc,0,1), axis=1) \n",
    "    \n",
    "#     ##Nonconformity score of the test set\n",
    "#     test_svmnc2_score = np.mean(np.delete(test_svmnc1_score,0,2), axis=2)\n",
    "#     test_rfnc2_score = np.mean(np.delete(test_rfnc1_score,0,2), axis=2)\n",
    "#     test_lrnc2_score = np.mean(np.delete(test_lrnc1_score,0,2), axis=2)\n",
    "#     test_gbcnc2_score = np.mean(np.delete(test_gbcnc1_score,0,2), axis=2)\n",
    "    \n",
    "#     ##The probability vector of the test set\n",
    "#     test_proba_svm_ = np.mean(np.delete(test_svm1_proba,0,2), axis=2)\n",
    "#     test_proba_rf_ = np.mean(np.delete(test_rf1_proba,0,2), axis=2)\n",
    "#     test_proba_lr_ = np.mean(np.delete(test_lr1_proba,0,2), axis=2)\n",
    "#     test_proba_gbc_ = np.mean(np.delete(test_gbc1_proba,0,2), axis=2)\n",
    "\n",
    "# ##The statistical vector of the test set    \n",
    "# test_p_svm_ = non_condition_p(cal_scores2_svm, test_svmnc2_score)\n",
    "# test_p_rf_ = non_condition_p(cal_scores2_rf, test_rfnc2_score)\n",
    "# test_p_lr_ = non_condition_p(cal_scores2_lr, test_lrnc2_score)   \n",
    "# test_p_gbc_ = non_condition_p(cal_scores2_gbc, test_gbcnc2_score)    \n",
    "# test_group_it = np.hstack((test_proba_svm_, test_proba_rf_, test_proba_lr_, test_proba_gbc_, \n",
    "#                            test_p_svm_, test_p_rf_, test_p_lr_, test_p_gbc_))\n",
    "# test_group_it = preprocessing.scale(test_group_it) \n",
    "\n",
    "\n",
    "# ##Determine whether the prediction of the original model is correct\n",
    "# discarded_sample = [] \n",
    "# accept_sample = [] \n",
    "# discarded_right_sample = [] \n",
    "# accept_right_sample = [] \n",
    "# accept_or_reject = []   \n",
    "# dis_test = np.empty((test_group_it.shape[0],class_num),float)\n",
    "# for aa in range(class_num):\n",
    "#     aa_prob = joblib.load('./save_model/clf_p_prob_%s'%aa+'.model')\n",
    "#     dis_test[:,aa] = aa_prob.decision_function(test_group_it).flatten()            \n",
    "# for t in range(len(y_pred_dif)):\n",
    "#         result_it_d = np.argmax(dis_test[t,:])\n",
    "#         svmit = joblib.load('./save_model/clf_pit.model')\n",
    "#         result_it = svmit.predict(test_group_it[t].reshape(1,-1))\n",
    "#         if (y_pred_dif[t] == result_it == result_it_d):\n",
    "#             accept_sample.append(t)\n",
    "#             accept_or_reject.append(1)\n",
    "#             if(y_pred_dif[t] == y_true_dif[t]):\n",
    "#                 accept_right_sample.append(t)\n",
    "#         else:\n",
    "#             discarded_sample.append(t)\n",
    "#             accept_or_reject.append(-1)\n",
    "#             if(y_pred_dif[t] == y_true_dif[t]):\n",
    "#                 discarded_right_sample.append(t)   \n",
    "                \n",
    "# print('\\n---------------  Evaluate the ability of the underlying model to predict the test data -----------------\\n') \n",
    "# print(accept_or_reject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf692a9",
   "metadata": {},
   "source": [
    "## Step 4. The performance of the RISE.\n",
    "Accuracy: The ratio of the number of correctly predicted samples to the total number of testing samples.  \n",
    "Precision：Of all detected drifting samples, how many are correct?  \n",
    "Recall：Of all drifting samples, how many are actually detected by Rise?  \n",
    "F1-score：A high F1-score means Rise can detect most drifting samples while rarely mis-classifying normal samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205a1102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------------ The performance of the RISE --------------------\n",
      "\n",
      "True Positive: 24\n",
      "False Positive: 0\n",
      "False Negative: 3\n",
      "True Negative: 153\n",
      "Accuracy: 0.9833333333333333\n",
      "Precision: 1.0\n",
      "Recall: 0.8888888888888888\n",
      "F1_Score: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "discarded_sample = np.load(filepath_AR + 'discarded_sample.npy')\n",
    "discarded_right_sample = np.load(filepath_AR + 'discarded_right_sample.npy')\n",
    "accept_sample = np.load(filepath_AR + 'accept_sample.npy')\n",
    "accept_right_sample = np.load(filepath_AR + 'accept_right_sample.npy')\n",
    "\n",
    "reject_num = len(discarded_sample) \n",
    "reject_num_right =  len(discarded_right_sample) \n",
    "accept_num = len(accept_sample) \n",
    "accept_num_right = len(accept_right_sample) \n",
    "\n",
    "TP = reject_num - reject_num_right\n",
    "FP = reject_num_right\n",
    "FN = accept_num - accept_num_right\n",
    "TN = accept_num_right\n",
    "\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1_Score = 2 * Precision * Recall / (Precision + Recall)\n",
    "\n",
    "print('\\n ------------------ The performance of the RISE --------------------\\n')\n",
    "print('True Positive:',TP)\n",
    "print('False Positive:',FP)\n",
    "print('False Negative:',FN)\n",
    "print('True Negative:', TN)\n",
    "print('Accuracy:',Accuracy)\n",
    "print('Precision:',Precision)\n",
    "print('Recall:',Recall)\n",
    "print('F1_Score:', F1_Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622fc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
